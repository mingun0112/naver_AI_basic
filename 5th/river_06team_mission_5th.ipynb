{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mingun0112/naver_AI_basic/blob/main/5th/river_06team_mission_5th.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dZ_LpGL7mmn"
      },
      "source": [
        "# Q1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY0iNeJ-7mms"
      },
      "source": [
        "가장 먼저 학습 데이터를 준비해보도록 하겠습니다.\n",
        "\n",
        "MNIST 데이터셋을 직접 Load해 봅시다.\n",
        "\n",
        "데이터셋을 로드하고 DataLoader를 구현해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3TYbHBLn7mmt"
      },
      "source": [
        "- DataLoader를 이용해 MNIST 데이터셋을 로드해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYfTLhWU7mmt",
        "outputId": "5e8bd563-24ff-446e-e7b2-8d6ac3209145"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jeojoyoung/miniconda3/envs/AI_Basic_torch/lib/python3.8/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/Users/jeojoyoung/miniconda3/envs/AI_Basic_torch/lib/python3.8/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN2at4_ops19empty_memory_format4callEN3c108ArrayRefIxEENS2_8optionalINS2_10ScalarTypeEEENS5_INS2_6LayoutEEENS5_INS2_6DeviceEEENS5_IbEENS5_INS2_12MemoryFormatEEE\n",
            "  Referenced from: /Users/jeojoyoung/miniconda3/envs/AI_Basic_torch/lib/python3.8/site-packages/torchvision/image.so\n",
            "  Expected in: /Users/jeojoyoung/miniconda3/envs/AI_Basic_torch/lib/python3.8/site-packages/torch/lib/libtorch_cpu.dylib\n",
            "  warn(f\"Failed to load image Python extension: {e}\")\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9WjIDFb7mmv",
        "outputId": "6df2fca7-8792-484f-8467-c209323dfd74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "0.5%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "63.5%IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "99.3%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "102.8%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "14.7%IOPub message rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_msg_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n",
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "112.7%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "training_epochs = 15\n",
        "batch_size = 100\n",
        "\n",
        "root = './data'\n",
        "mnist_train = dset.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
        "mnist_test = dset.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
        "\n",
        "# data loader를 직접 구현해보자.\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAOrpB0K7mmw"
      },
      "source": [
        "# Q2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWar5Ae57mmx"
      },
      "source": [
        "데이터가 준비가 되었다면, 이제 그 데이터를 학습할 모델을 구현할 차례입니다.\n",
        "\n",
        "그 후 모델 안의 가중치를 초기화시켜보세요.\n",
        "\n",
        "입력 데이터 형태에 맞도록 linear한 모델을 구성해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrRn4TxH7mmy"
      },
      "source": [
        "- MNIST 입력의 크기는 28x28 입니다.\n",
        "- 여기서 구현하는 linear 모델은 입력이 1차원이기 때문에 입력 차원을 맞춰보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG23PssS7mm0",
        "outputId": "31fa2a58-1a1a-410b-e9e5-ec375e1d0dfe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[-1.3176, -0.1216,  0.8522,  ...,  0.6451,  0.8641,  0.2506],\n",
              "        [-0.8071,  1.0029,  0.1269,  ..., -1.9281,  0.5311,  0.5487],\n",
              "        [-0.5804, -1.6175, -1.6585,  ...,  0.7464,  2.5960,  2.2398],\n",
              "        ...,\n",
              "        [-0.8532, -0.0527,  0.3537,  ...,  0.9529, -0.3284,  0.2590],\n",
              "        [-0.3046, -0.0795, -0.5848,  ...,  0.1577, -0.3409,  1.6728],\n",
              "        [-0.3879, -0.3335, -0.0547,  ...,  0.2423,  0.6444,  0.2639]],\n",
              "       requires_grad=True)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "linear = nn.Linear(784, 10, bias=True).to(device)\n",
        "nn.init.normal_(linear.weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKENjfat7mm2"
      },
      "source": [
        "# Q3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdtfUnJw7mm3"
      },
      "source": [
        "위에서 구현한 모델을 학습시키기 위해서는 loss 함수와 optimizer가 필요합니다.\n",
        "\n",
        "아래 제시된 loss 함수와 optimizer를 구현해보세요.\n",
        "\n",
        "Loss 함수와 optimizer는 모델 안의 가중치를 업데이트 할 때 사용됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OH9niZ17mm4"
      },
      "source": [
        "- 옵티마이저는 SGD, Loss는 Cross Entropy Loss를 사용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o8AGPCK7mm4"
      },
      "outputs": [],
      "source": [
        "# Loss fn - Cross Entropy Loss\n",
        "criterion = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "# optimizer - SGD\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eo1N2yRB7mm4"
      },
      "source": [
        "# Q4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnbjPRYn7mm5"
      },
      "source": [
        "3번 문제까지 해결하셨다면, 이제 학습을 위한 준비는 거의 끝났다고 볼 수 있습니다.\n",
        "\n",
        "위 구현 함수들을 이용해 학습 Loop를 구현해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8P8Kytd7mm5"
      },
      "source": [
        "- 위에서 구현한 모델, optimizer, loss fn 등을 이용해 학습을 구현해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTH4-Efj7mm5",
        "outputId": "2aefdeda-e233-4509-af48-49eba97120ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/15, Step [100/600], Loss: 4.378800, Accuracy: 36.00%\n",
            "Epoch [1/15, Step [200/600], Loss: 2.752653, Accuracy: 48.00%\n",
            "Epoch [1/15, Step [300/600], Loss: 1.775991, Accuracy: 69.00%\n",
            "Epoch [1/15, Step [400/600], Loss: 1.276452, Accuracy: 69.00%\n",
            "Epoch [1/15, Step [500/600], Loss: 1.536917, Accuracy: 68.00%\n",
            "Epoch [1/15, Step [600/600], Loss: 1.237475, Accuracy: 73.00%\n",
            "Epoch [2/15, Step [100/600], Loss: 1.206622, Accuracy: 75.00%\n",
            "Epoch [2/15, Step [200/600], Loss: 0.977483, Accuracy: 78.00%\n",
            "Epoch [2/15, Step [300/600], Loss: 1.682102, Accuracy: 74.00%\n",
            "Epoch [2/15, Step [400/600], Loss: 1.197460, Accuracy: 80.00%\n",
            "Epoch [2/15, Step [500/600], Loss: 1.159385, Accuracy: 75.00%\n",
            "Epoch [2/15, Step [600/600], Loss: 0.503960, Accuracy: 90.00%\n",
            "Epoch [3/15, Step [100/600], Loss: 0.819585, Accuracy: 86.00%\n",
            "Epoch [3/15, Step [200/600], Loss: 0.729808, Accuracy: 83.00%\n",
            "Epoch [3/15, Step [300/600], Loss: 1.333087, Accuracy: 75.00%\n",
            "Epoch [3/15, Step [400/600], Loss: 0.434241, Accuracy: 89.00%\n",
            "Epoch [3/15, Step [500/600], Loss: 1.030009, Accuracy: 80.00%\n",
            "Epoch [3/15, Step [600/600], Loss: 1.311180, Accuracy: 77.00%\n",
            "Epoch [4/15, Step [100/600], Loss: 0.720912, Accuracy: 78.00%\n",
            "Epoch [4/15, Step [200/600], Loss: 0.718994, Accuracy: 90.00%\n",
            "Epoch [4/15, Step [300/600], Loss: 0.754542, Accuracy: 84.00%\n",
            "Epoch [4/15, Step [400/600], Loss: 0.679800, Accuracy: 83.00%\n",
            "Epoch [4/15, Step [500/600], Loss: 1.045369, Accuracy: 77.00%\n",
            "Epoch [4/15, Step [600/600], Loss: 0.619369, Accuracy: 89.00%\n",
            "Epoch [5/15, Step [100/600], Loss: 0.825402, Accuracy: 80.00%\n",
            "Epoch [5/15, Step [200/600], Loss: 0.774051, Accuracy: 82.00%\n",
            "Epoch [5/15, Step [300/600], Loss: 0.533272, Accuracy: 89.00%\n",
            "Epoch [5/15, Step [400/600], Loss: 0.797285, Accuracy: 82.00%\n",
            "Epoch [5/15, Step [500/600], Loss: 0.748624, Accuracy: 88.00%\n",
            "Epoch [5/15, Step [600/600], Loss: 0.942538, Accuracy: 81.00%\n",
            "Epoch [6/15, Step [100/600], Loss: 0.664151, Accuracy: 86.00%\n",
            "Epoch [6/15, Step [200/600], Loss: 0.637175, Accuracy: 89.00%\n",
            "Epoch [6/15, Step [300/600], Loss: 0.532416, Accuracy: 89.00%\n",
            "Epoch [6/15, Step [400/600], Loss: 0.504870, Accuracy: 89.00%\n",
            "Epoch [6/15, Step [500/600], Loss: 0.459642, Accuracy: 87.00%\n",
            "Epoch [6/15, Step [600/600], Loss: 0.586337, Accuracy: 85.00%\n",
            "Epoch [7/15, Step [100/600], Loss: 0.409457, Accuracy: 88.00%\n",
            "Epoch [7/15, Step [200/600], Loss: 0.469002, Accuracy: 90.00%\n",
            "Epoch [7/15, Step [300/600], Loss: 0.831171, Accuracy: 83.00%\n",
            "Epoch [7/15, Step [400/600], Loss: 0.267463, Accuracy: 92.00%\n",
            "Epoch [7/15, Step [500/600], Loss: 0.749853, Accuracy: 87.00%\n",
            "Epoch [7/15, Step [600/600], Loss: 0.418141, Accuracy: 89.00%\n",
            "Epoch [8/15, Step [100/600], Loss: 0.524743, Accuracy: 89.00%\n",
            "Epoch [8/15, Step [200/600], Loss: 0.722628, Accuracy: 86.00%\n",
            "Epoch [8/15, Step [300/600], Loss: 0.610081, Accuracy: 88.00%\n",
            "Epoch [8/15, Step [400/600], Loss: 0.501472, Accuracy: 91.00%\n",
            "Epoch [8/15, Step [500/600], Loss: 0.398431, Accuracy: 89.00%\n",
            "Epoch [8/15, Step [600/600], Loss: 0.491220, Accuracy: 92.00%\n",
            "Epoch [9/15, Step [100/600], Loss: 0.283916, Accuracy: 91.00%\n",
            "Epoch [9/15, Step [200/600], Loss: 0.499676, Accuracy: 89.00%\n",
            "Epoch [9/15, Step [300/600], Loss: 0.516631, Accuracy: 91.00%\n",
            "Epoch [9/15, Step [400/600], Loss: 0.597306, Accuracy: 82.00%\n",
            "Epoch [9/15, Step [500/600], Loss: 0.423095, Accuracy: 86.00%\n",
            "Epoch [9/15, Step [600/600], Loss: 0.699190, Accuracy: 82.00%\n",
            "Epoch [10/15, Step [100/600], Loss: 0.790358, Accuracy: 85.00%\n",
            "Epoch [10/15, Step [200/600], Loss: 0.215139, Accuracy: 92.00%\n",
            "Epoch [10/15, Step [300/600], Loss: 0.566703, Accuracy: 82.00%\n",
            "Epoch [10/15, Step [400/600], Loss: 0.551365, Accuracy: 89.00%\n",
            "Epoch [10/15, Step [500/600], Loss: 0.260895, Accuracy: 89.00%\n",
            "Epoch [10/15, Step [600/600], Loss: 0.436652, Accuracy: 89.00%\n",
            "Epoch [11/15, Step [100/600], Loss: 0.811050, Accuracy: 88.00%\n",
            "Epoch [11/15, Step [200/600], Loss: 0.330083, Accuracy: 92.00%\n",
            "Epoch [11/15, Step [300/600], Loss: 0.378690, Accuracy: 87.00%\n",
            "Epoch [11/15, Step [400/600], Loss: 0.588784, Accuracy: 89.00%\n",
            "Epoch [11/15, Step [500/600], Loss: 0.252514, Accuracy: 94.00%\n",
            "Epoch [11/15, Step [600/600], Loss: 0.820063, Accuracy: 87.00%\n",
            "Epoch [12/15, Step [100/600], Loss: 0.810954, Accuracy: 80.00%\n",
            "Epoch [12/15, Step [200/600], Loss: 0.190848, Accuracy: 95.00%\n",
            "Epoch [12/15, Step [300/600], Loss: 0.553853, Accuracy: 87.00%\n",
            "Epoch [12/15, Step [400/600], Loss: 0.538094, Accuracy: 90.00%\n",
            "Epoch [12/15, Step [500/600], Loss: 0.732516, Accuracy: 81.00%\n",
            "Epoch [12/15, Step [600/600], Loss: 0.642626, Accuracy: 86.00%\n",
            "Epoch [13/15, Step [100/600], Loss: 0.505596, Accuracy: 87.00%\n",
            "Epoch [13/15, Step [200/600], Loss: 0.357383, Accuracy: 90.00%\n",
            "Epoch [13/15, Step [300/600], Loss: 0.547383, Accuracy: 88.00%\n",
            "Epoch [13/15, Step [400/600], Loss: 0.380503, Accuracy: 88.00%\n",
            "Epoch [13/15, Step [500/600], Loss: 0.316963, Accuracy: 91.00%\n",
            "Epoch [13/15, Step [600/600], Loss: 0.729925, Accuracy: 85.00%\n",
            "Epoch [14/15, Step [100/600], Loss: 0.510385, Accuracy: 88.00%\n",
            "Epoch [14/15, Step [200/600], Loss: 0.618558, Accuracy: 83.00%\n",
            "Epoch [14/15, Step [300/600], Loss: 1.040268, Accuracy: 79.00%\n",
            "Epoch [14/15, Step [400/600], Loss: 0.353278, Accuracy: 89.00%\n",
            "Epoch [14/15, Step [500/600], Loss: 0.968251, Accuracy: 80.00%\n",
            "Epoch [14/15, Step [600/600], Loss: 0.192717, Accuracy: 92.00%\n",
            "Epoch [15/15, Step [100/600], Loss: 0.708737, Accuracy: 86.00%\n",
            "Epoch [15/15, Step [200/600], Loss: 0.168048, Accuracy: 96.00%\n",
            "Epoch [15/15, Step [300/600], Loss: 0.352897, Accuracy: 90.00%\n",
            "Epoch [15/15, Step [400/600], Loss: 0.273129, Accuracy: 91.00%\n",
            "Epoch [15/15, Step [500/600], Loss: 0.606773, Accuracy: 89.00%\n",
            "Epoch [15/15, Step [600/600], Loss: 0.384913, Accuracy: 89.00%\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(training_epochs):\n",
        "    for i, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        imgs = imgs.view(-1, 28 * 28)\n",
        "\n",
        "        outputs = linear(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()   # optimizer zero grad 구현\n",
        "        loss.backward()         # loss backward 구현\n",
        "        optimizer.step()        # optimizer step 구현\n",
        "\n",
        "        _, argmax = torch.max(outputs, 1)\n",
        "        accuracy = (labels == argmax).float().mean()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}, Step [{}/{}], Loss: {:4f}, Accuracy: {:.2f}%'.format(\n",
        "                epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item() * 100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3y2IGzn47mm6"
      },
      "source": [
        "# Q5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nb1GfJg7mm6"
      },
      "source": [
        "학습이 완료되면, 모델이 잘 작동하는지 테스트가 필요합니다.\n",
        "\n",
        "데이터로드 파트에서 준비했던 테스트 데이터를 이용해 테스트를 진행해봅시다.\n",
        "\n",
        "아래 테스트 코드를 완성해보세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV3GbzLO7mm6",
        "outputId": "6ce0ca13-f914-4d77-8d07-84d116e841ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test accuracy for 10000 images: 89.35%\n"
          ]
        }
      ],
      "source": [
        "linear.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for i, (imgs, labels) in enumerate(test_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        imgs = imgs.view(-1, 28 * 28)\n",
        "\n",
        "        outputs = linear(imgs)\n",
        "\n",
        "        _, argmax = torch.max(outputs, 1) # max()를 통해 최종 출력이 가장 높은 class 선택\n",
        "        total += imgs.size(0)\n",
        "        correct += (labels == argmax).sum().item()\n",
        "\n",
        "print('Test accuracy for {} images: {:.2f}%'.format(total, correct / total * 100))"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "35e7390a3fe5450e79d2f81e1122d1ab6549eccf6bae3bee461d739cdaff0940"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "river_06team_mission_5th.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}